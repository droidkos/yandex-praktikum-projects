{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "import transformers\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея нижеследующих блоков в том, чтобы обучить модель без нейронок, посмотреть, сможем ли выжать приемлемый результат без них (хорошо бы, если так), а потом повторить обучение на PyTorch+BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение классическим ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом блоке проведем обучение и тест без нейронных сетей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    #lemm_list = stemmer.lemmatize(text)\n",
    "    lemm_list = [stemmer.stem(word) for word in text]\n",
    "    lemm_text = \"\".join(lemm_list)\n",
    "        \n",
    "    return lemm_text\n",
    "\n",
    "def clear_text(text):\n",
    "    reed = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    splitted = reed.split()\n",
    "    joined = \" \".join(splitted)\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем копии выборок, то же сделаем для блока с нейронками, для лучшей сравнимости результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets, test_tweets = train.copy(), test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем лемматизацию и очистку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweets['lemm_text'] = train['text'].apply(lemmatize)\n",
    "train_tweets['lemm_text'] = train_tweets['lemm_text'].apply(clear_text)\n",
    "test_tweets['lemm_text'] = test['text'].apply(lemmatize)\n",
    "test_tweets['lemm_text'] = test_tweets['lemm_text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем список стоп-слов из библиотеки NTLK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train, corpus_test = train_tweets['lemm_text'].values.astype('U'), \\\n",
    "                            test_tweets['lemm_text'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производим векторизацию (при этом fit делаем только на обучающей выборке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "count_tf_idf.fit(corpus_train)\n",
    "tf_idf_train = count_tf_idf.transform(corpus_train)\n",
    "tf_idf_test = count_tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Модель логистической регрессии </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=300, solver='liblinear', class_weight='balanced')\n",
    "score1 = cross_val_score(model, tf_idf_train, train.toxic, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7472438636262243\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=300, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf_idf_train, train.toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = model.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.7588 \n",
      "Precision: 0.6829 \n",
      "Recall 0.8537\n"
     ]
    }
   ],
   "source": [
    " print(\"F1:\", f1_score(test.toxic, pred_lr).round(4), '\\nPrecision:',\n",
    "       precision_score(test.toxic, pred_lr).round(4), '\\nRecall', recall_score(test.toxic, pred_lr).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34186  1620]\n",
      " [  598  3489]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test.toxic, pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Градиентный бустинг на деревьях </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целях экономии времени, я решил остановиться на одной модели бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgmb = lgb.LGBMClassifier(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = cross_val_score(model_lgmb, tf_idf_train, train.toxic, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(score2).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toxic.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я очень хотел применить нейронки, в итоге не смог получить какой-то выдающийся результат, в лучшем случае F1=0.72. Была испробована модель bert_uncased и вторая, distilbert, используемая ниже. В документации сказано, она хорошо подходит для семантического анализа и более легковесна чем собсвенно BERT. Эмбединги генерировались около 3 часов, поэтому я сохранил результат в csv-файл и в представленной версии ноутбука признаки и ответы берутся оттуда. Сам процесс обучения оставляю в закомментированном виде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tweets = train_tweets.sample(30000).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "# pt_model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(model_name, model_max_length=512, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors = tokenizer(df_tweets.lemm_text.to_list(), padding=True, truncation=True, max_length=512, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 10\n",
    "# embeddings = []\n",
    "# for i in notebook.tqdm(range(df_tweets.shape[0] // batch_size)):\n",
    "    \n",
    "#         tmp_batch = tensors.data['input_ids'][batch_size*i:batch_size*(i+1)]\n",
    "#         attention_mask_batch = tensors.data['attention_mask'][batch_size*i:batch_size*(i+1)]\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             batch_embeddings = pt_model(tmp_batch, output_hidden_states=True, output_attentions=True,\n",
    "#                                        attention_mask=attention_mask_batch)\n",
    "\n",
    "#         embeddings.append(batch_embeddings[1][-1][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Важный дисклеймер\n",
    "\n",
    "Эмбединги сверху считаются на моем ПК около трех часов (с учетом того, что я не являюсь обладателем даже consumer-grade видеокарты Nvidia, не говоря уже о чем-то более серьезном). Выборка неполная (30000 строк), но качество вряд ли станет лучше на полной (и у меня столько оперативной памяти нет).\n",
    "\n",
    "Поэтому сгрузил готовые эмбеддинги в виде файлов csv. К сожалению, облака не предоставляют прямые ссылки на файлы, а гитхаб такие большие и вовсе принимать отказывается. Пришлось прибегнуть к помощи Google Colab, там готовая среда и точно все запустится.\n",
    "\n",
    "Правда, проблему с подгрузкой файла не и там не удалось как-то красиво решить.\n",
    "\n",
    "Поэтому, если есть возможность, посмотрите вторую часть по ссылке ниже. Для просмотра никаких доп. манипуляций не требуется, однако если вы сочтете возможным, там есть мини-инструкция по подгрузке файлов с эмбеддингами, после чего код можно выполнять.\n",
    "\n",
    "Очень много времени потратил на работу с этой моделью, не хотелось выбрасывать, даже несмотря на не самый лучший результат.\n",
    "\n",
    "Спасибо за понимание. Потом можно сразу пролистать к выводам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1XTw1X7BS-_p9h03uH0ffCf_9BTzr7ouS?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = np.concatenate(embeddings)\n",
    "# target = df_tweets['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = np.loadtxt(r'D:\\features_new_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = pd.read_csv(r'D:\\target_new.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = LogisticRegression(max_iter=500, random_state=12345, solver='liblinear', C=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cross_val_score(model2, features, target, scoring='f1').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сплит, чтобы посмотреть характер ошибок модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(features, target, stratify=target, test_size=0.1, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Ручной\" фит + предикт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.fit(X_train, y_train)\n",
    "# pred_nn = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"F1:\", f1_score(y_test, pred_nn).round(4), '\\nPrecision:',\n",
    "#       precision_score(y_test, pred_nn).round(4), '\\nRecall', recall_score(y_test, pred_nn).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица ошибок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(confusion_matrix(y_test, pred_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевой класс в трети случаев не опознан - плохая модель, в прод я бы такое постыдился выпускать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим вероятности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probas = model2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Небольшой перебор порогов классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(0.2, 0.8, 0.1):\n",
    "#     preds_by_hand = [0 if pred_pos < i else 1 for pred_neg, pred_pos in probas]\n",
    "#     print(i, 'is', f1_score(y_test, preds_by_hand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = pd.read_csv(r'D:\\features_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таки дожали 0.75, но в целом провал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.DataFrame(df_tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_train, test_test = train_test_split(test, test_size=0.1, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_test['real'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_test['pred'] = pred_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте мы решали задачу семантической классификации текстов. В ходе работы обучили модели логистической регрессии и градиентного бустинга на деревьях, применив TD-IDF и очистку, используя регулярные выражения. Необходимый уровень целевой метрики F1 был достигнут.\n",
    "\n",
    "Очень много времени было потрачено на нейросеть BERT (точнее, я использовал вариант Distibert, согласно документации эта модель хорошо подходит именно для задачи классификации. хотя обычный BERT тоже пробовал). К сожалению, в итоге данная модель все равно оказалась сравнима или даже хуже простой логистической регрессии (или бустинга на деревьях), а с учетом времени обучения и затрат вычислительных ресурсов ее попросту нецелесобразно пускать в продакшн. В качестве возможной причины тауой низкой результативности я бы обозначил шум в данных, в частности, я выборочно просмотрел тексты, попадаются и куски иноязычного текста попадаются (не английский), и разного рода сленг. Кроме того, отдельно посмотрел примеры, где модель не смогла правильно выделить целевой класс (ложноотрицательные ответы), если бы я размечал данные, не все бы пометил как токсичные. Т.е. задача неочевидная даже с точки зрения человека, что уж говорить о машине.\n",
    "\n",
    "Преподаватель также высказывался, что некоторые датасеты с легкостью берет обычная регрессия, а другие даже  лучшим моделям не под силу. У меня впечатление, что мы имеем второй случай. Думаю, модель BERT может выдавать гораздо лучший результат, а если запускать ее на подходящем оборудовании, то и с производительностью не будет больших проблем."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
